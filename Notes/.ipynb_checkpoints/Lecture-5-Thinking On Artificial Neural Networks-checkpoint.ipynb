{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于人工神经网络模型的若干思考\n",
    "\n",
    "Author：周建山 BY1613123\n",
    "\n",
    "Email：jianshanzhou@foxmail.com\n",
    "\n",
    "Web：https://github.com/JianshanZhou/Computing-Intelligence-Course.git\n",
    "\n",
    "+ \"**人工神经网络在何种程度上模拟了人脑神经系统的微观结构和行为响应关系，其目的何在?**\"\n",
    "\n",
    "    人工神经网络（Artificial Nerual Networks, ANN）模型本质上属于数学意义上的一种“**映射**”，该模型的建立启发于人脑神经系统中神经元接收外部环境信号刺激而做出动态的响应行为以及启发于多个神经元相互之间交互式的“激励/抑制”行为。人工神经网络属于“连接主义”模型，至少在三个方面模拟了人脑神经系统的动态响应行为：（1）**个体动力性的模拟**：人工神经网络中单个神经元采用某种特定的激励函数（Activation Function）来模拟人脑系统中神经元接受刺激后的响应行为，而且，不同的神经元可以采用不同的激励函数，这体现了人工神经网络中神经元个体的差异性；（2）**群体关联性的模拟**：利用网络的几何形式来刻画人脑系统中多个神经元之间的关联性，具体的网络拓扑结构则对应模拟了人脑神经系统中实现某种特定功能的多个神经元的几何关系，神经元之间的连接权表征了他们之间的关联程度（相互影响的程度）；（3）**群体动力性的模拟**：人工神经网络的学习过程主要包括两个阶段，第一个阶段是“信息前馈”——也可以视为“系统响应”，另一个阶段是“误差反馈”——可以视为“系统矫正”；在每一个阶段中，除了输入层神经元之外，每一个神经元的输入刺激信号都和其他神经元的响应行为息息相关，每个神经元的响应误差都受到其他神经元的响应误差的影响，也就是说，单个神经元的响应动力性包含着其他与之关联的神经元的响应动力性，因此，人工神经网络的动态行为具有群体性。本质上，人工神经网络体现了大自然（生物系统）中普遍存在的一种“群体智能”特性：**即使支配单个个体（决策）行为的法则可以十分简单，但是，多个个体通过某种特定的关联形式相互作用，便能够涌现出十分复杂的行为——而这种群体行为能够使这些个体所构成的系统整体具备“认知、适应、优化”等“智能”特性**，人工神经网络的目的则是模拟这种系统的智能性以解决特定背景下的问题。\n",
    "    \n",
    "\n",
    "+ “**从MP模型到感知机模型，再到含有隐层的BP网络，其组织结构的进化与功能的增强说明了什么?**”\n",
    "    \n",
    "    从人工神经网络的发展历程来看，从简单的感知机模型到BP网络，再到目前广为应用的Deep Learning Networks，随着所面临问题的复杂程度（数据量增加、数据特征复杂）的增加，人工神经网络数学模型的复杂程度及其训练算法的复杂程度也在增加——这个演进过程给人的最大体会是——“**世界所呈现的面目是复杂的**”。复杂化的网络结构在一定程度上增强了其自身“模拟生物系统”的能力——从而获得更好的“智能性”——这反过来也体现了“生物系统（人脑神经系统）”在整体层面上的“复杂性”。随着脑学科、神经学科等领域的发展，人们对人脑系统的组成、结构、功能等机理的认知程度不断加深，促进了人工神经网络模型的发展。另一方面，由于人工神经网络是从数学（计算）的角度来模拟生物系统行为，在实际工程应用中，这种“计算”的实现还受限于计算机软硬件资源的条件——例如，当前深度学习算法之所以能够被广泛应用，其中一个很大的原因在于当前计算机技术（GPU、CPU硬件能力）有了很大进步。但是，值得指出的是：“世界所呈现的面目是复杂的”并不一定意味着“支配世界的本质是复杂的”。是否存在一种或者一套“简单（形式意义上）”的算法来模拟物理世界的“复杂”行为——例如，生物系统的智能性？这依旧是一个难以定论的问题。\n",
    "\n",
    "\n",
    "+ “**人工神经网络在模拟人脑智能行为方面的关键要素是什么，其计算智能水平又体现在哪些方面?**”\n",
    "\n",
    "    正如前面所提及的，人工神经网络在模拟人脑智能行为方面的关键要素主要包括：（1）模拟个体动力性的激励函数；（2）模拟多个个体之间拓扑关系的网络几何结构；（3）模拟群体动力性的学习机制（训练算法），其计算智能水平体现在个体动力性和群体动力性两大层面——使得整个系统具备自组织、自由化、自适应（学习）能力。\n",
    "\n",
    "\n",
    "+ “**监督学习和无监督学习各有什么特点?其内在机制上的区别是什么?在实际应用中如何发挥其优势?**”\n",
    "\n",
    "    **监督学习**的特点在于：用于训练模型的数据样本包括目标变量（因变量）和用来预测目标变量的预测变量（自变量）两大部分，通常，这些样本中的“因变量”称为“标签”而“自变量”称为“属性”。利用这些“属性-标签“的样本对来训练一个模型，使模型具备一种特定的“映射”能力：给定某一个特定的“属性”数据作为输入，模型能够判断这个输入的”属性“是对应于哪个“标签”（输出“标签”）。\n",
    "    \n",
    "    **无监督学习**的特点在于：用于训练模型的数据样本仅仅包括自变量（“属性”）部分而没有因变量（“标签”）。利用这些属性样本训练一个模型，使之能够表达这些属性样本的特征以及他们之间的关联性，亦即，具有相同（相似）特征——也就是在某一种意义下关联性紧密的——属性样本被划分为同一种“类”（cluster）。\n",
    "    \n",
    "    通常，为了充分发挥“无监督学习”和“有监督”学习算法的优势，在给定一个数据集的情况下，作为数据的预处理和初步分析，可以利用“无监督学习算法”（例如K-means聚类、SOM自组织聚类、DBSCAN聚类等）处理分析这些数据集，发现其中的特征类和种特征类的分布情况；然后，在这个基础上，利用“有监督学习算法”（例如深度学习、BP算法等）有目的地在各种特征类的样本集上训练模型。\n",
    "    \n",
    "+ “**应用人工神经网络解决问题应该在哪些地方下功夫?从Hopfield网络求解TSP问题的成功范例中想到什么?**”\n",
    "\n",
    "    个人认为：人工神经网络本身是一种比较复杂的模型，为了成功将其应用于解决某种问题，首先，要求模型设计者**对该问题的特定背景及其具体问题的业务逻辑（目标、约束等的数学表达）有较为深入的认知**；其次，要求模型设计者具备改进人工神经网络模型的经验——针对具体问题的求解效果**进行参数调优的经验**。应用人工神经网络解决实际问题，该模型的一个很大的“缺陷”在于其“学习收敛速度”和“过拟合”问题——为了克服网络在某些特定数据样本集上学习收敛速度慢、容易陷入具备最优状态的缺点，通常可以改变神经元的激励函数和目标函数的设计——除了sigmoid函数还可以采用其他（例如，双曲正切、高斯核函数、softmax函数等）作为激励函数，而除了可以采用最小均方形式的目标函数，还可以采用Cross entropy函数作为目标函数；为了抑制网络的“过拟合”缺点，在设计目标函数的结构时候，可以引入“正则化”（regulation）项，或者在学习过程中采用Dropout策略，或者增加数据样本的多样性等。总而言之，当前，学界和业界已经提出了各种各样的tricks来提高人工神经网络模型在某一问题领域的应用能力，而对这些tricks的理解和掌握，是模型设计者需要“下功夫”的地方。\n",
    "    \n",
    "    Hopfield网络能够应用于求解TSP问题，本质上归功于网络“能量”函数的数学形式和TSP问题的目标+约束的数学形式具有可类比性，因此，能够针对一个给定的TSP问题（目标和约束）来设计一个”能量“函数和TSP解对应的“状态”，这个能量函数和状态即对应于一个Hopfield网络。但是，Hopfield网络迭代收敛于状态空间的平衡点（吸引子）——这种吸引子通常只是局部最优的——甚至，并不一定收敛于有效状态（可行解）。从本课程的数值实验结果可知，采用Hopfield网络求解TSP问题需要通过引入“惩罚系数”将TSP的优化目标和约束条件转化为一个“无约束”优化问题的目标函数——Hopfield网络本质上求解的是这个“无约束”优化问题。Hopfield网络在求解小规模TSP时候并不能保证获得最优解，而且，模型的参数和初始化设置对模型收敛结果有很大影响，Hopfield等学者的早期相关研究同样指出，当应对超过30个节点、乃至大规模的TSP问题，Hopfield网络并不一定能获得较好的收敛性、优化性，而且，模型对参数的设置比较敏感。这些情况就决定了Hopfield网络在求解TSP问题的局限性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
